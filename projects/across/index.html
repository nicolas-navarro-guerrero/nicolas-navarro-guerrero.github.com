---
layout: projects
slug: "/projects/across/"

date: "2023-04-01"
enddate: "2026-03-31"
title: "ACROSS: Adaptive Cross-Modal Representation for Robotic Transfer Learning"
subtitle: ""

funded: 
grant: 
coordinator: "Nicolás Navarro-Guerrero, Forschungszentrum L3S, Leibniz Universität Hannover﻿"
staff: Wadhah Zai El Amri
acknowledgments: 
partners: Nicolás Navarro-Guerrero
sponsors: 
thumbnail: "/projects/across/ACROSS-logo-light.png"
tags: [project, research, luh, hannover, l3s, haptic, tactile perception]
relatedpapers: across
---

<p>A glaring problem in robotics is the re-utilization of data and solutions. While data and code can be shared, they cannot be directly deployed on other robotic systems as they might differ in configuration, performance, sensor array, etc. Similarly, the data cannot be simply aggregated into a more extensive dataset. Hence, training from scratch for a particular robotic system is still the norm.</p>

<p>Tactile perception is a good example of this challenge because tactile data is strongly dependent on the robot hand or gripper used and the type of sensor. Moreover, unlike cameras (RGB), tactile sensors have no standard data representation. Additionally, tactile and proprioceptive data are intrinsically active, i.e., the explorative movements are key for recognition.</p>

<p>This project aims to develop a unified representation of tactile data. Such representation could allow efficient and effective robotic systems to operate across diverse modalities and robots. Another aim is to reuse knowledge from other robotic systems. The outcomes of this project aim to improve object recognition, object manipulation, and robot dexterity. However, the applications of this type of transfer and representation learning time go beyond these use cases and robotics applications.</p>

